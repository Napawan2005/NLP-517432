{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtXd2ID1AacazP3zA+3HXX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Napawan2005/NLP-517432/blob/main/Word_Representation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xL5exQB7B4QV"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?',\n",
        "]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit(corpus)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ectorizer.fit_transform(corpus)` การนำเข้า model CountVectorizer"
      ],
      "metadata": {
        "id": "_J2GqsuRCj7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`vectorizer.get_feature_names_out()` คำที่ไม่ซ้ำกัน"
      ],
      "metadata": {
        "id": "IiwTIK4dCX_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O15mfp-iC2Ou",
        "outputId": "80c42e54-4f02-402a-a485-df93eca10085"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFEcwI5xDLgj",
        "outputId": "53ca998f-8d72-4c46-a19a-33ee6903b949"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
              "       'this'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**หาคำซ้ำจากคลัง index**"
      ],
      "metadata": {
        "id": "GgLnkd8JDw50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tansform = vectorizer.transform(corpus)\n",
        "print(X_tansform.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNFPnVUODZ9-",
        "outputId": "d4aaa7cd-d72f-4726-dfa3-287d8beae851"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
        "X2 = vectorizer2.fit(corpus)\n",
        "print(f\"X2.vocabulary_  :\\n {X2.vocabulary_}\")\n",
        "print(X2.get_feature_names_out())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNXZxTqCCBPA",
        "outputId": "b0ed518b-2b33-4429-81d8-e4bb19b18e5c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X2.vocabulary_  :\n",
            " {'this is': 11, 'is the': 3, 'the first': 6, 'first document': 2, 'this document': 10, 'document is': 1, 'the second': 7, 'second document': 5, 'and this': 0, 'the third': 8, 'third one': 9, 'is this': 4, 'this the': 12}\n",
            "['and this' 'document is' 'first document' 'is the' 'is this'\n",
            " 'second document' 'the first' 'the second' 'the third' 'third one'\n",
            " 'this document' 'this is' 'this the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = vectorizer2.transform(corpus)\n",
        "print(x.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQXyCnjtER8h",
        "outputId": "eeaa51b2-28ae-4911-fc76-1c45b2c135dc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
            " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
            " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
            " [0 0 1 0 1 0 1 0 0 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = vectorizer2.fit_transform(corpus)\n",
        "print(X2.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KugK6SUeEU_2",
        "outputId": "06d6b6c2-c540-4e16-ff5a-6b9e05544b7e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
            " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
            " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
            " [0 0 1 0 1 0 1 0 0 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "สามารถทำได้ 2 วิธีคือการ fit แล้วค่อย tranform\n",
        " หรือ ทำทั้ง 2 อย่างโดยใช้คำสั่ง `.fit_transform(corpus)`"
      ],
      "metadata": {
        "id": "7gwf8Z3_EY8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer2.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oil8SJlD-_4",
        "outputId": "5e0c6fd5-a6b0-417a-db9c-9d288c80ffa2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and this', 'document is', 'first document', 'is the', 'is this',\n",
              "       'second document', 'the first', 'the second', 'the third',\n",
              "       'third one', 'this document', 'this is', 'this the'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "v2 = CountVectorizer( ngram_range=(1, 2))\n",
        "x2_vectorizer = v2.fit(corpus)\n",
        "print(\"Vocabulary:\", x2_vectorizer.vocabulary_)\n",
        "x2_transformed = x2_vectorizer.transform(corpus)\n",
        "print(\"Shape of Count Vectorized Matrix:\", x2_transformed.shape)\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "x2_normalized = tfidf_transformer.fit_transform(x2_transformed)\n",
        "print(\"Shape of Normalized (TF-IDF) Matrix:\", x2_normalized.shape)\n",
        "print(\"Normalized (TF-IDF) Array:\\n\", x2_normalized.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXzTs3s1EpSM",
        "outputId": "19d46e74-9e6d-4c01-c093-e6dfe77e94a5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: {'this': 18, 'is': 6, 'the': 12, 'first': 4, 'document': 2, 'this is': 20, 'is the': 7, 'the first': 13, 'first document': 5, 'second': 10, 'this document': 19, 'document is': 3, 'the second': 14, 'second document': 11, 'and': 0, 'third': 16, 'one': 9, 'and this': 1, 'the third': 15, 'third one': 17, 'is this': 8, 'this the': 21}\n",
            "Shape of Count Vectorized Matrix: (4, 22)\n",
            "Shape of Normalized (TF-IDF) Matrix: (4, 22)\n",
            "Normalized (TF-IDF) Array:\n",
            " [[0.         0.         0.3145322  0.         0.38850984 0.38850984\n",
            "  0.25715068 0.3145322  0.         0.         0.         0.\n",
            "  0.25715068 0.38850984 0.         0.         0.         0.\n",
            "  0.25715068 0.         0.38850984 0.        ]\n",
            " [0.         0.         0.45551258 0.35682424 0.         0.\n",
            "  0.18620569 0.22775629 0.         0.         0.35682424 0.35682424\n",
            "  0.18620569 0.         0.35682424 0.         0.         0.\n",
            "  0.18620569 0.35682424 0.         0.        ]\n",
            " [0.35700721 0.35700721 0.         0.         0.         0.\n",
            "  0.18630117 0.22787308 0.         0.35700721 0.         0.\n",
            "  0.18630117 0.         0.         0.35700721 0.35700721 0.35700721\n",
            "  0.18630117 0.         0.28146859 0.        ]\n",
            " [0.         0.         0.28293955 0.         0.34948664 0.34948664\n",
            "  0.23132162 0.         0.44327948 0.         0.         0.\n",
            "  0.23132162 0.34948664 0.         0.         0.         0.\n",
            "  0.23132162 0.         0.         0.44327948]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-9CtCcW9KjIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?',\n",
        "]\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n"
      ],
      "metadata": {
        "id": "ZoVMhoYCE06c"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(X.toarray)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJJiY60jKq8v",
        "outputId": "6c789cfe-697a-465f-f029-53550fc8454b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 9)\n",
            "<bound method _cs_matrix.toarray of <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 21 stored elements and shape (4, 9)>>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vJjMX571K0ef"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}